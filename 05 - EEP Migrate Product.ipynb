{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cad20eb3",
   "metadata": {},
   "source": [
    "# Product Data Migration to Strapi API\n",
    "\n",
    "This notebook processes product data from CSV and uploads it to the Strapi database via API.\n",
    "\n",
    "## Important Notes:\n",
    "- **Parent Products Only**: Filters out product variants (those with hyphens in SKU or Frame/Print Size)\n",
    "- **Foreign Key Relationships**: Links to Artists, Campaigns, Colours, and EAN Groups\n",
    "- **Batch Processing**: Uploads 50 products at a time with checkpoints\n",
    "- **Image URLs**: Stores URLs in product_artwork_url (images uploaded separately later)\n",
    "- **Resume Capability**: Can resume from last checkpoint if interrupted\n",
    "\n",
    "## Process:\n",
    "1. Load CSV data and filter parent products\n",
    "2. Build lookup dictionaries from API (Artists, Campaigns, Colours, EANs)\n",
    "3. Prepare product records with foreign key lookups\n",
    "4. Batch upload with checkpoints and error tracking\n",
    "5. Generate detailed report\n",
    "\n",
    "## Field Mapping:\n",
    "- CSV: `Name` → API: `product_parent_name`\n",
    "- CSV: `SKU` → API: `product_sku`\n",
    "- CSV: `Artist` → API: `artist` (foreign key)\n",
    "- CSV: `EEP Campaign Name` → API: `campaigns` (foreign key array)\n",
    "- CSV: `Primary Colour` → API: `primary_colours` (foreign key array)\n",
    "- CSV: `Secondary Colour` → API: `secondary_colours` (foreign key array)\n",
    "- CSV: `EAN Group` → API: `ean_group` (foreign key)\n",
    "- CSV: `Unbxd Primary Image URL` → API: `product_artwork_url`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66d8938f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:26:59,803 - INFO - API Base URL: http://localhost:1337/api\n",
      "2025-10-23 13:26:59,804 - INFO - API Token loaded successfully\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import json\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import logging\n",
    "from typing import Dict, List, Optional, Set\n",
    "import time\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# API Configuration\n",
    "API_BASE_URL = os.getenv('API_BASE_URL')\n",
    "API_TOKEN = os.getenv('API_TOKEN')\n",
    "\n",
    "if not API_BASE_URL or not API_TOKEN:\n",
    "    raise ValueError(\"API_BASE_URL and API_TOKEN must be set in .env file\")\n",
    "\n",
    "logger.info(f\"API Base URL: {API_BASE_URL}\")\n",
    "logger.info(\"API Token loaded successfully\")\n",
    "\n",
    "# Batch configuration\n",
    "BATCH_SIZE = 50\n",
    "DELAY_BETWEEN_BATCHES = 2  # seconds\n",
    "DELAY_BETWEEN_UPLOADS = 0.5  # seconds between individual uploads\n",
    "CHECKPOINT_FILE = 'product_migration_checkpoint.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a382900f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:00,834 - INFO - Loading CSV file: data/All Product Data Back Up 070825.csv\n",
      "/var/folders/5m/1db7tmxj0xl9lp3_7cnxt1vw0000gn/T/ipykernel_44482/2487177708.py:30: DtypeWarning: Columns (34) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path, usecols=columns_to_load)\n",
      "2025-10-23 13:27:11,786 - INFO - Successfully loaded 384349 rows from CSV\n",
      "2025-10-23 13:27:11,788 - INFO - Columns: ['SKU (Unique Id)', 'Unbxd Primary Image URL (productImage)', 'Weight', 'Product Type', 'Orientation', 'Primary Colour', 'Secondary Colour', 'Depth', 'Name (productName)', 'Keywords', 'Height', 'Artist', 'Width', 'SKU (Parent ID) (parent_id)', 'Frame Style (Child only)', 'Print Size (Child only)', 'EAN Group', 'Set Size', 'EEP Campaign Name']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 5 rows of data:\n",
      "       SKU (Unique Id)             Unbxd Primary Image URL (productImage)  \\\n",
      "0            13PRIN001  https://pim-assets.unbxd.com/images/5f46a02207...   \n",
      "1   13PRIN001-30x40-BB  https://pim-assets.unbxd.com/images/5f46a02207...   \n",
      "2  13PRIN001-30x40-MBF  https://pim-assets.unbxd.com/images/5f46a02207...   \n",
      "3  13PRIN001-30x40-MOF  https://pim-assets.unbxd.com/images/5f46a02207...   \n",
      "4  13PRIN001-30x40-MWF  https://pim-assets.unbxd.com/images/5f46a02207...   \n",
      "\n",
      "   Weight       Product Type Orientation Primary Colour Secondary Colour  \\\n",
      "0    0.03  Digital Art Print    Portrait          Green              NaN   \n",
      "1    0.03  Digital Art Print    Portrait          Green              NaN   \n",
      "2    0.93  Digital Art Print    Portrait          Green              NaN   \n",
      "3    0.93  Digital Art Print    Portrait          Green              NaN   \n",
      "4    0.93  Digital Art Print    Portrait          Green              NaN   \n",
      "\n",
      "   Depth Name (productName)  \\\n",
      "0   0.05    Born To Be Wild   \n",
      "1   0.05    Born To Be Wild   \n",
      "2   2.20    Born To Be Wild   \n",
      "3   2.20    Born To Be Wild   \n",
      "4   2.20    Born To Be Wild   \n",
      "\n",
      "                                            Keywords  Height         Artist  \\\n",
      "0  13PRIN001,The13Prints,BornToBeWild,Floral,Typo...    42.0  The 13 Prints   \n",
      "1  13PRIN001,The13Prints,BornToBeWild,Floral,Typo...    40.0  The 13 Prints   \n",
      "2  13PRIN001,The13Prints,BornToBeWild,Floral,Typo...    43.4  The 13 Prints   \n",
      "3  13PRIN001,The13Prints,BornToBeWild,Floral,Typo...    43.4  The 13 Prints   \n",
      "4  13PRIN001,The13Prints,BornToBeWild,Floral,Typo...    43.4  The 13 Prints   \n",
      "\n",
      "   Width SKU (Parent ID) (parent_id) Frame Style (Child only)  \\\n",
      "0   29.7                         NaN                      NaN   \n",
      "1   30.0                   13PRIN001                       BB   \n",
      "2   33.4                   13PRIN001                      MBF   \n",
      "3   33.4                   13PRIN001                      MOF   \n",
      "4   33.4                   13PRIN001                      MWF   \n",
      "\n",
      "  Print Size (Child only)   EAN Group Set Size        EEP Campaign Name  \n",
      "0                     NaN         NaN      NaN  Fun - Colour Your Walls  \n",
      "1                   30x40  50566943.0      NaN  Fun - Colour Your Walls  \n",
      "2                   30x40  50566943.0      NaN  Fun - Colour Your Walls  \n",
      "3                   30x40  50566943.0      NaN  Fun - Colour Your Walls  \n",
      "4                   30x40  50566943.0      NaN  Fun - Colour Your Walls  \n",
      "\n",
      "Data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 384349 entries, 0 to 384348\n",
      "Data columns (total 19 columns):\n",
      " #   Column                                  Non-Null Count   Dtype  \n",
      "---  ------                                  --------------   -----  \n",
      " 0   SKU (Unique Id)                         384349 non-null  object \n",
      " 1   Unbxd Primary Image URL (productImage)  384327 non-null  object \n",
      " 2   Weight                                  384348 non-null  float64\n",
      " 3   Product Type                            384348 non-null  object \n",
      " 4   Orientation                             384196 non-null  object \n",
      " 5   Primary Colour                          384238 non-null  object \n",
      " 6   Secondary Colour                        141604 non-null  object \n",
      " 7   Depth                                   384348 non-null  float64\n",
      " 8   Name (productName)                      384349 non-null  object \n",
      " 9   Keywords                                384328 non-null  object \n",
      " 10  Height                                  384348 non-null  float64\n",
      " 11  Artist                                  381721 non-null  object \n",
      " 12  Width                                   384348 non-null  float64\n",
      " 13  SKU (Parent ID) (parent_id)             375621 non-null  object \n",
      " 14  Frame Style (Child only)                371287 non-null  object \n",
      " 15  Print Size (Child only)                 371278 non-null  object \n",
      " 16  EAN Group                               366674 non-null  float64\n",
      " 17  Set Size                                892 non-null     object \n",
      " 18  EEP Campaign Name                       384328 non-null  object \n",
      "dtypes: float64(5), object(14)\n",
      "memory usage: 55.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Load CSV data\n",
    "csv_file_path = 'data/All Product Data Back Up 070825.csv'\n",
    "\n",
    "logger.info(f\"Loading CSV file: {csv_file_path}\")\n",
    "\n",
    "# Columns to load (using exact column names from CSV)\n",
    "columns_to_load = [\n",
    "    'Name (productName)',\n",
    "    'SKU (Unique Id)',\n",
    "    'SKU (Parent ID) (parent_id)',\n",
    "    'Artist',\n",
    "    'Product Type',\n",
    "    'Orientation',\n",
    "    'Weight',\n",
    "    'Height',\n",
    "    'Width',\n",
    "    'Depth',\n",
    "    'Primary Colour',\n",
    "    'Secondary Colour',\n",
    "    'EAN Group',\n",
    "    'EEP Campaign Name',\n",
    "    'Keywords',\n",
    "    'Set Size',\n",
    "    'Frame Style (Child only)',\n",
    "    'Print Size (Child only)',\n",
    "    'Unbxd Primary Image URL (productImage)'\n",
    "]\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_file_path, usecols=columns_to_load)\n",
    "    logger.info(f\"Successfully loaded {len(df)} rows from CSV\")\n",
    "    logger.info(f\"Columns: {df.columns.tolist()}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst 5 rows of data:\")\n",
    "    print(df.head())\n",
    "    \n",
    "    print(\"\\nData info:\")\n",
    "    print(df.info())\n",
    "    \n",
    "except Exception as e:\n",
    "    logger.error(f\"Error loading CSV file: {e}\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f96b9b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:11,929 - INFO - Filtering for parent products only...\n",
      "2025-10-23 13:27:14,969 - INFO - Total rows in CSV: 384349\n",
      "2025-10-23 13:27:14,969 - INFO - Parent products: 12964\n",
      "2025-10-23 13:27:14,970 - INFO - Variants (filtered out): 371385\n",
      "2025-10-23 13:27:14,973 - INFO - Unique parent products after deduplication: 8717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample parent products:\n",
      "                                    Name (productName) SKU (Unique Id)  \\\n",
      "0                                      Born To Be Wild       13PRIN001   \n",
      "67            Born To Be Wild Greetings Card Pack of 6      13PRIN001c   \n",
      "68                                       Cheeky Monkey       13PRIN002   \n",
      "135                                         Ey Up Duck       13PRIN003   \n",
      "202                Ey Up Duck Greetings Card Pack of 6      13PRIN003c   \n",
      "203                                 Get Off Your Phone       13PRIN004   \n",
      "270                   Home Sweet Home by The 13 Prints       13PRIN005   \n",
      "337  Home Sweet Home by The 13 Prints Greetings Car...      13PRIN005c   \n",
      "338                            Let The Good Times Roll       13PRIN006   \n",
      "405                                    Live In The Now       13PRIN007   \n",
      "\n",
      "            Artist       Product Type  \n",
      "0    The 13 Prints  Digital Art Print  \n",
      "67   The 13 Prints               Card  \n",
      "68   The 13 Prints  Digital Art Print  \n",
      "135  The 13 Prints  Digital Art Print  \n",
      "202  The 13 Prints               Card  \n",
      "203  The 13 Prints  Digital Art Print  \n",
      "270  The 13 Prints  Digital Art Print  \n",
      "337  The 13 Prints               Card  \n",
      "338  The 13 Prints  Digital Art Print  \n",
      "405  The 13 Prints  Digital Art Print  \n",
      "\n",
      "Sample variants (excluded):\n",
      "   Name (productName)      SKU (Unique Id) Frame Style (Child only)  \\\n",
      "1     Born To Be Wild   13PRIN001-30x40-BB                       BB   \n",
      "2     Born To Be Wild  13PRIN001-30x40-MBF                      MBF   \n",
      "3     Born To Be Wild  13PRIN001-30x40-MOF                      MOF   \n",
      "4     Born To Be Wild  13PRIN001-30x40-MWF                      MWF   \n",
      "5     Born To Be Wild  13PRIN001-30x40-TBF                      TBF   \n",
      "6     Born To Be Wild  13PRIN001-30x40-TOF                      TOF   \n",
      "7     Born To Be Wild  13PRIN001-30x40-TWF                      TWF   \n",
      "8     Born To Be Wild   13PRIN001-30x40-UF                       UF   \n",
      "9     Born To Be Wild  13PRIN001-30x40-WBF                      WBF   \n",
      "10    Born To Be Wild  13PRIN001-30x40-WOF                      WOF   \n",
      "\n",
      "   Print Size (Child only)  \n",
      "1                    30x40  \n",
      "2                    30x40  \n",
      "3                    30x40  \n",
      "4                    30x40  \n",
      "5                    30x40  \n",
      "6                    30x40  \n",
      "7                    30x40  \n",
      "8                    30x40  \n",
      "9                    30x40  \n",
      "10                   30x40  \n"
     ]
    }
   ],
   "source": [
    "# Filter for parent products only (exclude variants)\n",
    "def is_parent_product(row) -> bool:\n",
    "    \"\"\"\n",
    "    Determine if a row represents a parent product (not a variant).\n",
    "    \n",
    "    Method 1: Check for hyphen in SKU (variants have hyphens like \"SKU-A1\" or \"SKU-White-A2\")\n",
    "    Method 2: Check Frame Style and Print Size columns (variants have these filled)\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row\n",
    "        \n",
    "    Returns:\n",
    "        True if parent product, False if variant\n",
    "    \"\"\"\n",
    "    # Method 1: Check SKU for hyphen\n",
    "    sku = str(row['SKU (Unique Id)']).strip() if pd.notna(row['SKU (Unique Id)']) else ''\n",
    "    has_hyphen = '-' in sku\n",
    "    \n",
    "    # Method 2: Check Frame Style and Print Size\n",
    "    frame_style = row['Frame Style (Child only)']\n",
    "    print_size = row['Print Size (Child only)']\n",
    "    \n",
    "    has_frame = pd.notna(frame_style) and str(frame_style).strip() != ''\n",
    "    has_print = pd.notna(print_size) and str(print_size).strip() != ''\n",
    "    \n",
    "    # Parent product must have:\n",
    "    # - No hyphen in SKU AND\n",
    "    # - No Frame Style or Print Size\n",
    "    is_parent = not has_hyphen and not (has_frame or has_print)\n",
    "    \n",
    "    return is_parent\n",
    "\n",
    "logger.info(\"Filtering for parent products only...\")\n",
    "\n",
    "# Apply filter\n",
    "df['is_parent'] = df.apply(is_parent_product, axis=1)\n",
    "parent_products_df = df[df['is_parent']].copy()\n",
    "\n",
    "logger.info(f\"Total rows in CSV: {len(df)}\")\n",
    "logger.info(f\"Parent products: {len(parent_products_df)}\")\n",
    "logger.info(f\"Variants (filtered out): {len(df) - len(parent_products_df)}\")\n",
    "\n",
    "# Remove duplicates by Name (product_parent_name)\n",
    "parent_products_df = parent_products_df.drop_duplicates(subset=['Name (productName)'], keep='first')\n",
    "logger.info(f\"Unique parent products after deduplication: {len(parent_products_df)}\")\n",
    "\n",
    "# Display sample parent products\n",
    "print(\"\\nSample parent products:\")\n",
    "print(parent_products_df[['Name (productName)', 'SKU (Unique Id)', 'Artist', 'Product Type']].head(10))\n",
    "\n",
    "# Display sample variants (for verification)\n",
    "variant_df = df[~df['is_parent']]\n",
    "if len(variant_df) > 0:\n",
    "    print(\"\\nSample variants (excluded):\")\n",
    "    print(variant_df[['Name (productName)', 'SKU (Unique Id)', 'Frame Style (Child only)', 'Print Size (Child only)']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd79033f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:16,646 - INFO - Building lookup dictionaries from API...\n",
      "2025-10-23 13:27:16,648 - INFO - Note: Strapi v5 uses FLAT structure - fields at root level, not nested\n",
      "2025-10-23 13:27:17,483 - INFO - Fetched 279 artists\n",
      "2025-10-23 13:27:17,484 - INFO - ✅ Artist lookup: 277 entries\n",
      "2025-10-23 13:27:17,712 - INFO - Fetched 54 campaigns\n",
      "2025-10-23 13:27:17,713 - INFO - ✅ Campaign lookup: 53 entries\n",
      "2025-10-23 13:27:17,919 - INFO - Fetched 12 colours\n",
      "2025-10-23 13:27:17,920 - INFO - ✅ Colour lookup: 12 entries\n",
      "2025-10-23 13:27:18,124 - INFO - Fetched 8 EAN groups\n",
      "2025-10-23 13:27:18,125 - INFO - ✅ EAN lookup: 8 entries\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "LOOKUP DICTIONARIES BUILT\n",
      "============================================================\n",
      "Artists: 277\n",
      "Campaigns: 53\n",
      "Colours: 12\n",
      "EAN Groups: 8\n",
      "\n",
      "Total: 350 entries\n",
      "\n",
      "📋 Sample artists (first 5):\n",
      "  '67 inc' → ID 574\n",
      "  'aley wild' → ID 580\n",
      "  'alice straker' → ID 582\n",
      "  'anek' → ID 594\n",
      "  'anna schmidt' → ID 600\n",
      "\n",
      "📋 All colours:\n",
      "  'black' → ID 2\n",
      "  'blue' → ID 4\n",
      "  'brown' → ID 6\n",
      "  'green' → ID 8\n",
      "  'grey' → ID 10\n",
      "  'orange' → ID 12\n",
      "  'pink' → ID 14\n",
      "  'purple' → ID 16\n",
      "  'red' → ID 18\n",
      "  'teal' → ID 20\n",
      "  'white' → ID 22\n",
      "  'yellow' → ID 24\n"
     ]
    }
   ],
   "source": [
    "# Build lookup dictionaries from API\n",
    "def fetch_all_entities(endpoint: str, entity_name: str) -> List[Dict]:\n",
    "    \"\"\"\n",
    "    Fetch all entities from a Strapi endpoint with pagination.\n",
    "    \n",
    "    Args:\n",
    "        endpoint: API endpoint (e.g., '/artists')\n",
    "        entity_name: Name for logging\n",
    "        \n",
    "    Returns:\n",
    "        List of all entities\n",
    "    \"\"\"\n",
    "    url = f\"{API_BASE_URL}{endpoint}\"\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    all_entities = []\n",
    "    page = 1\n",
    "    page_size = 100\n",
    "    \n",
    "    while True:\n",
    "        params = {\n",
    "            'pagination[page]': page,\n",
    "            'pagination[pageSize]': page_size\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            response = requests.get(url, headers=headers, params=params, timeout=30)\n",
    "            \n",
    "            if response.status_code == 200:\n",
    "                data = response.json()\n",
    "                entities = data.get('data', [])\n",
    "                all_entities.extend(entities)\n",
    "                \n",
    "                # Check if there are more pages\n",
    "                pagination = data.get('meta', {}).get('pagination', {})\n",
    "                if page >= pagination.get('pageCount', 1):\n",
    "                    break\n",
    "                    \n",
    "                page += 1\n",
    "            else:\n",
    "                logger.error(f\"Failed to fetch {entity_name}: {response.status_code}\")\n",
    "                logger.error(f\"Response: {response.text}\")\n",
    "                break\n",
    "                \n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching {entity_name}: {e}\")\n",
    "            break\n",
    "    \n",
    "    logger.info(f\"Fetched {len(all_entities)} {entity_name}\")\n",
    "    return all_entities\n",
    "\n",
    "# Build lookup dictionaries\n",
    "logger.info(\"Building lookup dictionaries from API...\")\n",
    "logger.info(\"Note: Strapi v5 uses FLAT structure - fields at root level, not nested\")\n",
    "\n",
    "# Artists: {name: id}\n",
    "artists = fetch_all_entities('/artists', 'artists')\n",
    "artist_lookup = {}\n",
    "for artist in artists:\n",
    "    # Strapi v5: Fields are directly on the object, NOT under 'attributes'\n",
    "    artist_id = artist.get('id')\n",
    "    name = artist.get('artist_name', '').strip().lower()\n",
    "    if name and artist_id:\n",
    "        artist_lookup[name] = artist_id\n",
    "logger.info(f\"✅ Artist lookup: {len(artist_lookup)} entries\")\n",
    "\n",
    "# Campaigns: {name: id}\n",
    "campaigns = fetch_all_entities('/campaigns', 'campaigns')\n",
    "campaign_lookup = {}\n",
    "for campaign in campaigns:\n",
    "    campaign_id = campaign.get('id')\n",
    "    name = campaign.get('campaign_name', '').strip().lower()\n",
    "    if name and campaign_id:\n",
    "        campaign_lookup[name] = campaign_id\n",
    "logger.info(f\"✅ Campaign lookup: {len(campaign_lookup)} entries\")\n",
    "\n",
    "# Colours: {name: id}\n",
    "colours = fetch_all_entities('/colours', 'colours')\n",
    "colour_lookup = {}\n",
    "for colour in colours:\n",
    "    colour_id = colour.get('id')\n",
    "    name = colour.get('colour_name', '').strip().lower()\n",
    "    if name and colour_id:\n",
    "        colour_lookup[name] = colour_id\n",
    "logger.info(f\"✅ Colour lookup: {len(colour_lookup)} entries\")\n",
    "\n",
    "# EAN Groups: {group: id}\n",
    "eans = fetch_all_entities('/eans', 'EAN groups')\n",
    "ean_lookup = {}\n",
    "for ean in eans:\n",
    "    ean_id = ean.get('id')\n",
    "    group = ean.get('ean_group', '').strip()\n",
    "    if group and ean_id:\n",
    "        ean_lookup[group] = ean_id\n",
    "logger.info(f\"✅ EAN lookup: {len(ean_lookup)} entries\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"LOOKUP DICTIONARIES BUILT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Artists: {len(artist_lookup)}\")\n",
    "print(f\"Campaigns: {len(campaign_lookup)}\")\n",
    "print(f\"Colours: {len(colour_lookup)}\")\n",
    "print(f\"EAN Groups: {len(ean_lookup)}\")\n",
    "print(f\"\\nTotal: {len(artist_lookup) + len(campaign_lookup) + len(colour_lookup) + len(ean_lookup)} entries\")\n",
    "\n",
    "# Show samples\n",
    "if artist_lookup:\n",
    "    print(f\"\\n📋 Sample artists (first 5):\")\n",
    "    for i, (name, id) in enumerate(list(artist_lookup.items())[:5]):\n",
    "        print(f\"  '{name}' → ID {id}\")\n",
    "if colour_lookup:\n",
    "    print(f\"\\n📋 All colours:\")\n",
    "    for name, id in sorted(colour_lookup.items()):\n",
    "        print(f\"  '{name}' → ID {id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b38300c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:30,168 - INFO - Helper functions defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Helper functions for data transformation\n",
    "\n",
    "def extract_colours(colour_value) -> List[str]:\n",
    "    \"\"\"\n",
    "    Extract individual colour names from a field that may contain multiple colours.\n",
    "    Reuses logic from colour migration.\n",
    "    \"\"\"\n",
    "    if pd.isna(colour_value):\n",
    "        return []\n",
    "    \n",
    "    colour_str = str(colour_value).strip()\n",
    "    \n",
    "    excluded_terms = [\n",
    "        'nan', 'none', 'n/a', 'unknown', '', \n",
    "        'multicoloured', 'multicolored', 'multi-coloured', 'multi-colored',\n",
    "        'various', 'mixed', 'assorted', 'multi', 'multiple'\n",
    "    ]\n",
    "    \n",
    "    if colour_str == '' or colour_str.lower() in excluded_terms:\n",
    "        return []\n",
    "    \n",
    "    # Split by common separators\n",
    "    colours = re.split(r'[,/&;]|\\band\\b', colour_str, flags=re.IGNORECASE)\n",
    "    \n",
    "    # Clean each colour name\n",
    "    cleaned_colours = []\n",
    "    for colour in colours:\n",
    "        colour = colour.strip().lower()\n",
    "        if colour and colour not in excluded_terms:\n",
    "            cleaned_colours.append(colour)\n",
    "    \n",
    "    return cleaned_colours\n",
    "\n",
    "def lookup_colour_ids(colour_names: List[str]) -> List[int]:\n",
    "    \"\"\"\n",
    "    Convert colour names to IDs using lookup dictionary.\n",
    "    \"\"\"\n",
    "    colour_ids = []\n",
    "    for colour_name in colour_names:\n",
    "        colour_id = colour_lookup.get(colour_name.lower())\n",
    "        if colour_id:\n",
    "            colour_ids.append(colour_id)\n",
    "        else:\n",
    "            logger.warning(f\"Colour not found in lookup: '{colour_name}'\")\n",
    "    return colour_ids\n",
    "\n",
    "def convert_to_metres(value, unit='cm') -> Optional[float]:\n",
    "    \"\"\"\n",
    "    Convert dimension values to metres.\n",
    "    Assumes CSV values are in cm unless specified.\n",
    "    \"\"\"\n",
    "    if pd.isna(value):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        val = float(value)\n",
    "        if unit == 'cm':\n",
    "            return val / 100  # Convert cm to metres\n",
    "        return val\n",
    "    except (ValueError, TypeError):\n",
    "        logger.warning(f\"Could not convert dimension value: {value}\")\n",
    "        return None\n",
    "\n",
    "def prepare_product_data(row) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Transform DataFrame row into API-compatible product data format.\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row containing product information\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary with API field names and values, or None if invalid\n",
    "    \"\"\"\n",
    "    # Skip if product name is missing\n",
    "    product_name = row['Name (productName)']\n",
    "    if pd.isna(product_name) or str(product_name).strip() == '':\n",
    "        logger.warning(\"Skipping product - missing name\")\n",
    "        return None\n",
    "    \n",
    "    product_data = {\n",
    "        \"product_parent_name\": str(product_name).strip(),\n",
    "    }\n",
    "    \n",
    "    # SKU (use Unique Id, fallback to Parent ID)\n",
    "    sku = row['SKU (Unique Id)'] if pd.notna(row['SKU (Unique Id)']) else row['SKU (Parent ID) (parent_id)']\n",
    "    if pd.notna(sku) and str(sku).strip() != '':\n",
    "        product_data['product_sku'] = str(sku).strip()\n",
    "    \n",
    "    # Product Type\n",
    "    if pd.notna(row['Product Type']):\n",
    "        product_data['product_type'] = str(row['Product Type']).strip()\n",
    "    \n",
    "    # Orientation\n",
    "    if pd.notna(row['Orientation']):\n",
    "        product_data['product_orientation'] = str(row['Orientation']).strip()\n",
    "    \n",
    "    # Dimensions (convert to metres)\n",
    "    if pd.notna(row['Weight']):\n",
    "        product_data['product_weight_kg'] = float(row['Weight'])\n",
    "    \n",
    "    height = convert_to_metres(row['Height'])\n",
    "    if height:\n",
    "        product_data['product_height_metres'] = height\n",
    "    \n",
    "    width = convert_to_metres(row['Width'])\n",
    "    if width:\n",
    "        product_data['product_width_metres'] = width\n",
    "    \n",
    "    depth = convert_to_metres(row['Depth'])\n",
    "    if depth:\n",
    "        product_data['product_depth_metres'] = depth\n",
    "    \n",
    "    # Set Size\n",
    "    if pd.notna(row['Set Size']):\n",
    "        try:\n",
    "            product_data['product_set_size'] = int(float(row['Set Size']))\n",
    "        except (ValueError, TypeError):\n",
    "            pass\n",
    "    \n",
    "    # Keywords\n",
    "    if pd.notna(row['Keywords']):\n",
    "        product_data['product_keywords'] = str(row['Keywords']).strip()\n",
    "    \n",
    "    # Image URL (store for later upload)\n",
    "    if pd.notna(row['Unbxd Primary Image URL (productImage)']):\n",
    "        product_data['product_artwork_url'] = str(row['Unbxd Primary Image URL (productImage)']).strip()\n",
    "    \n",
    "    # Foreign Key: Artist\n",
    "    if pd.notna(row['Artist']):\n",
    "        artist_name = str(row['Artist']).strip().lower()\n",
    "        artist_id = artist_lookup.get(artist_name)\n",
    "        if artist_id:\n",
    "            product_data['artist'] = artist_id\n",
    "        else:\n",
    "            logger.warning(f\"Artist not found: '{row['Artist']}'\")\n",
    "    \n",
    "    # Foreign Key: Campaign\n",
    "    if pd.notna(row['EEP Campaign Name']):\n",
    "        campaign_name = str(row['EEP Campaign Name']).strip().lower()\n",
    "        campaign_id = campaign_lookup.get(campaign_name)\n",
    "        if campaign_id:\n",
    "            product_data['campaigns'] = [campaign_id]\n",
    "        else:\n",
    "            logger.warning(f\"Campaign not found: '{row['EEP Campaign Name']}'\")\n",
    "    \n",
    "    # Foreign Key: Primary Colours\n",
    "    primary_colour_names = extract_colours(row['Primary Colour'])\n",
    "    if primary_colour_names:\n",
    "        primary_colour_ids = lookup_colour_ids(primary_colour_names)\n",
    "        if primary_colour_ids:\n",
    "            product_data['primary_colours'] = primary_colour_ids\n",
    "    \n",
    "    # Foreign Key: Secondary Colours\n",
    "    secondary_colour_names = extract_colours(row['Secondary Colour'])\n",
    "    if secondary_colour_names:\n",
    "        secondary_colour_ids = lookup_colour_ids(secondary_colour_names)\n",
    "        if secondary_colour_ids:\n",
    "            product_data['secondary_colours'] = secondary_colour_ids\n",
    "    \n",
    "    # Foreign Key: EAN Group\n",
    "    if pd.notna(row['EAN Group']):\n",
    "        ean_group = str(row['EAN Group']).strip()\n",
    "        ean_id = ean_lookup.get(ean_group)\n",
    "        if ean_id:\n",
    "            product_data['ean_group'] = ean_id\n",
    "        else:\n",
    "            logger.warning(f\"EAN Group not found: '{ean_group}'\")\n",
    "    \n",
    "    return product_data\n",
    "\n",
    "logger.info(\"Helper functions defined successfully\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4e1200b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:32,933 - INFO - Preparing product records...\n",
      "2025-10-23 13:27:33,519 - INFO - Prepared 8717 product records for upload\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample prepared product data (first 3):\n",
      "\n",
      "1. {\n",
      "  \"product_parent_name\": \"Born To Be Wild\",\n",
      "  \"product_sku\": \"13PRIN001\",\n",
      "  \"product_type\": \"Digital Art Print\",\n",
      "  \"product_orientation\": \"Portrait\",\n",
      "  \"product_weight_kg\": 0.03,\n",
      "  \"product_height_metres\": 0.42,\n",
      "  \"product_width_metres\": 0.297,\n",
      "  \"product_depth_metres\": 0.0005,\n",
      "  \"product_keywords\": \"13PRIN001,The13Prints,BornToBeWild,Floral,Typography,Green,\",\n",
      "  \"product_artwork_url\": \"https://pim-assets.unbxd.com/images/5f46a02207c906b25dc972bb16266bfa/1699663218948_683773_source_1682601330.jpg\",\n",
      "  \"artist\": 1046,\n",
      "  \"campaigns\": [\n",
      "    16\n",
      "  ],\n",
      "  \"primary_colours\": [\n",
      "    8\n",
      "  ]\n",
      "}\n",
      "\n",
      "2. {\n",
      "  \"product_parent_name\": \"Born To Be Wild Greetings Card Pack of 6\",\n",
      "  \"product_sku\": \"13PRIN001c\",\n",
      "  \"product_type\": \"Card\",\n",
      "  \"product_orientation\": \"Portrait\",\n",
      "  \"product_weight_kg\": 0.12,\n",
      "  \"product_height_metres\": 0.17,\n",
      "  \"product_width_metres\": 0.12,\n",
      "  \"product_depth_metres\": 0.03,\n",
      "  \"product_keywords\": \"13PRIN001c,The 13 Prints,Born To Be Wild,Botanical,Typography,Illustrative,Green,Black and White,Born To Be Wild ,nature, words, flowers,\",\n",
      "  \"product_artwork_url\": \"https://unbxd-pim-assets.s3.us-east-1.amazonaws.com/images/5f46a02207c906b25dc972bb16266bfa/1724154321/13PRIN001c_lrw-Product_Image_url.jpg\",\n",
      "  \"artist\": 1046,\n",
      "  \"campaigns\": [\n",
      "    36\n",
      "  ],\n",
      "  \"primary_colours\": [\n",
      "    8\n",
      "  ],\n",
      "  \"secondary_colours\": [\n",
      "    14\n",
      "  ],\n",
      "  \"ean_group\": 4\n",
      "}\n",
      "\n",
      "3. {\n",
      "  \"product_parent_name\": \"Cheeky Monkey\",\n",
      "  \"product_sku\": \"13PRIN002\",\n",
      "  \"product_type\": \"Digital Art Print\",\n",
      "  \"product_orientation\": \"Portrait\",\n",
      "  \"product_weight_kg\": 0.03,\n",
      "  \"product_height_metres\": 0.42,\n",
      "  \"product_width_metres\": 0.297,\n",
      "  \"product_depth_metres\": 0.0005,\n",
      "  \"product_keywords\": \"13PRIN002,The13Prints,CheekyMonkey,Monkey,Typography,Green,\",\n",
      "  \"product_artwork_url\": \"https://pim-assets.unbxd.com/images/5f46a02207c906b25dc972bb16266bfa/1699663222520_683903_source_1682601362.jpg\",\n",
      "  \"artist\": 1046,\n",
      "  \"campaigns\": [\n",
      "    16\n",
      "  ],\n",
      "  \"primary_colours\": [\n",
      "    8\n",
      "  ]\n",
      "}\n",
      "\n",
      "Total products to upload: 8717\n",
      "Total batches: 175\n"
     ]
    }
   ],
   "source": [
    "# Prepare all product records\n",
    "logger.info(\"Preparing product records...\")\n",
    "\n",
    "product_records = []\n",
    "skipped_count = 0\n",
    "\n",
    "for idx, row in parent_products_df.iterrows():\n",
    "    product_data = prepare_product_data(row)\n",
    "    if product_data:\n",
    "        product_records.append(product_data)\n",
    "    else:\n",
    "        skipped_count += 1\n",
    "\n",
    "logger.info(f\"Prepared {len(product_records)} product records for upload\")\n",
    "if skipped_count > 0:\n",
    "    logger.warning(f\"Skipped {skipped_count} invalid product records\")\n",
    "\n",
    "# Display sample prepared data\n",
    "print(\"\\nSample prepared product data (first 3):\")\n",
    "for i, record in enumerate(product_records[:3]):\n",
    "    print(f\"\\n{i+1}. {json.dumps(record, indent=2)}\")\n",
    "\n",
    "print(f\"\\nTotal products to upload: {len(product_records)}\")\n",
    "print(f\"Total batches: {(len(product_records) + BATCH_SIZE - 1) // BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5e3cb7a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:42,635 - INFO - Checkpoint functions defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "No existing checkpoint found. Will start fresh.\n"
     ]
    }
   ],
   "source": [
    "# Checkpoint management functions\n",
    "\n",
    "def save_checkpoint(batch_num: int, successful: List[str], failed: List[Dict]):\n",
    "    \"\"\"\n",
    "    Save current progress to a checkpoint file.\n",
    "    \n",
    "    This allows resuming if the process is interrupted.\n",
    "    \n",
    "    Args:\n",
    "        batch_num: Current batch number (last completed)\n",
    "        successful: List of successfully uploaded product names\n",
    "        failed: List of failed uploads with error info\n",
    "    \"\"\"\n",
    "    checkpoint_data = {\n",
    "        'last_batch': batch_num,\n",
    "        'timestamp': datetime.now().isoformat(),\n",
    "        'successful_uploads': successful,\n",
    "        'failed_uploads': failed,\n",
    "        'total_processed': len(successful) + len(failed)\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, 'w') as f:\n",
    "            json.dump(checkpoint_data, f, indent=2)\n",
    "        logger.info(f\"Checkpoint saved: batch {batch_num}, {len(successful)} successful, {len(failed)} failed\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save checkpoint: {e}\")\n",
    "\n",
    "def load_checkpoint() -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Load checkpoint from file if it exists.\n",
    "    \n",
    "    Returns:\n",
    "        Checkpoint data dict or None if no checkpoint exists\n",
    "    \"\"\"\n",
    "    if not os.path.exists(CHECKPOINT_FILE):\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        with open(CHECKPOINT_FILE, 'r') as f:\n",
    "            checkpoint = json.load(f)\n",
    "        logger.info(f\"Loaded checkpoint: batch {checkpoint['last_batch']}, \"\n",
    "                   f\"{len(checkpoint['successful_uploads'])} successful, \"\n",
    "                   f\"{len(checkpoint['failed_uploads'])} failed\")\n",
    "        return checkpoint\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load checkpoint: {e}\")\n",
    "        return None\n",
    "\n",
    "def clear_checkpoint():\n",
    "    \"\"\"\n",
    "    Remove checkpoint file (call when migration completes successfully).\n",
    "    \"\"\"\n",
    "    if os.path.exists(CHECKPOINT_FILE):\n",
    "        try:\n",
    "            os.remove(CHECKPOINT_FILE)\n",
    "            logger.info(\"Checkpoint file cleared\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Failed to clear checkpoint: {e}\")\n",
    "\n",
    "logger.info(\"Checkpoint functions defined\")\n",
    "\n",
    "# Check for existing checkpoint\n",
    "existing_checkpoint = load_checkpoint()\n",
    "if existing_checkpoint:\n",
    "    print(\"\\n⚠️  EXISTING CHECKPOINT FOUND!\")\n",
    "    print(f\"Last batch completed: {existing_checkpoint['last_batch']}\")\n",
    "    print(f\"Successful uploads: {len(existing_checkpoint['successful_uploads'])}\")\n",
    "    print(f\"Failed uploads: {len(existing_checkpoint['failed_uploads'])}\")\n",
    "    print(f\"Timestamp: {existing_checkpoint['timestamp']}\")\n",
    "    print(\"\\nYou can resume from this checkpoint in the upload cell.\")\n",
    "else:\n",
    "    print(\"\\nNo existing checkpoint found. Will start fresh.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "71a170c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:46,909 - INFO - Product creation function defined successfully\n"
     ]
    }
   ],
   "source": [
    "# Function to create product via API\n",
    "def create_product(product_data: Dict) -> Optional[Dict]:\n",
    "    \"\"\"\n",
    "    Create a product record in the Strapi database via API.\n",
    "    \n",
    "    Args:\n",
    "        product_data: Dictionary containing product information\n",
    "        \n",
    "    Returns:\n",
    "        Response data if successful, None if failed\n",
    "    \"\"\"\n",
    "    endpoint = f\"{API_BASE_URL}/products\"\n",
    "    \n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {API_TOKEN}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    \n",
    "    # Prepare payload according to Strapi format\n",
    "    payload = {\n",
    "        \"data\": product_data\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(endpoint, headers=headers, json=payload, timeout=30)\n",
    "        \n",
    "        if response.status_code == 200 or response.status_code == 201:\n",
    "            logger.info(f\"Successfully created product: {product_data.get('product_parent_name')}\")\n",
    "            return response.json()\n",
    "        else:\n",
    "            logger.error(f\"Failed to create product {product_data.get('product_parent_name')}: {response.status_code}\")\n",
    "            logger.error(f\"Response: {response.text}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        logger.error(f\"Network error creating product {product_data.get('product_parent_name')}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error creating product {product_data.get('product_parent_name')}: {e}\")\n",
    "        return None\n",
    "\n",
    "logger.info(\"Product creation function defined successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2ed2eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-23 13:27:50,062 - INFO - Starting product upload process...\n",
      "2025-10-23 13:27:50,063 - INFO - Total products: 8717\n",
      "2025-10-23 13:27:50,064 - INFO - Batch size: 50\n",
      "2025-10-23 13:27:50,064 - INFO - Total batches: 175\n",
      "2025-10-23 13:27:50,065 - INFO - Starting from batch: 1\n",
      "2025-10-23 13:27:50,065 - INFO - \n",
      "============================================================\n",
      "2025-10-23 13:27:50,066 - INFO - Processing batch 1/175 (products 1-50)\n",
      "2025-10-23 13:27:50,066 - INFO - ============================================================\n",
      "2025-10-23 13:27:50,066 - INFO - Uploading product 1/8717: Born To Be Wild\n",
      "2025-10-23 13:27:51,719 - INFO - Successfully created product: Born To Be Wild\n",
      "2025-10-23 13:27:52,225 - INFO - Uploading product 2/8717: Born To Be Wild Greetings Card Pack of 6\n",
      "2025-10-23 13:27:52,368 - ERROR - Failed to create product Born To Be Wild Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:27:52,369 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:27:52,874 - INFO - Uploading product 3/8717: Cheeky Monkey\n",
      "2025-10-23 13:27:54,205 - INFO - Successfully created product: Cheeky Monkey\n",
      "2025-10-23 13:27:54,711 - INFO - Uploading product 4/8717: Ey Up Duck\n",
      "2025-10-23 13:27:56,048 - INFO - Successfully created product: Ey Up Duck\n",
      "2025-10-23 13:27:56,554 - INFO - Uploading product 5/8717: Ey Up Duck Greetings Card Pack of 6\n",
      "2025-10-23 13:27:56,644 - ERROR - Failed to create product Ey Up Duck Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:27:56,644 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:27:57,150 - INFO - Uploading product 6/8717: Get Off Your Phone\n",
      "2025-10-23 13:27:58,287 - INFO - Successfully created product: Get Off Your Phone\n",
      "2025-10-23 13:27:58,793 - INFO - Uploading product 7/8717: Home Sweet Home by The 13 Prints\n",
      "2025-10-23 13:28:00,083 - INFO - Successfully created product: Home Sweet Home by The 13 Prints\n",
      "2025-10-23 13:28:00,590 - INFO - Uploading product 8/8717: Home Sweet Home by The 13 Prints Greetings Card Pack of 6\n",
      "2025-10-23 13:28:00,677 - ERROR - Failed to create product Home Sweet Home by The 13 Prints Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:00,678 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:01,188 - INFO - Uploading product 9/8717: Let The Good Times Roll\n",
      "2025-10-23 13:28:02,573 - INFO - Successfully created product: Let The Good Times Roll\n",
      "2025-10-23 13:28:03,085 - INFO - Uploading product 10/8717: Live In The Now\n",
      "2025-10-23 13:28:04,185 - INFO - Successfully created product: Live In The Now\n",
      "2025-10-23 13:28:04,692 - INFO - Uploading product 11/8717: Love Is The Whole Thing\n",
      "2025-10-23 13:28:05,854 - INFO - Successfully created product: Love Is The Whole Thing\n",
      "2025-10-23 13:28:06,356 - INFO - Uploading product 12/8717: Oh Baby It's A Wild World\n",
      "2025-10-23 13:28:07,555 - INFO - Successfully created product: Oh Baby It's A Wild World\n",
      "2025-10-23 13:28:08,058 - INFO - Uploading product 13/8717: Rise Up by The 13 Prints\n",
      "2025-10-23 13:28:09,446 - INFO - Successfully created product: Rise Up by The 13 Prints\n",
      "2025-10-23 13:28:09,950 - INFO - Uploading product 14/8717: Seas The Day\n",
      "2025-10-23 13:28:11,359 - INFO - Successfully created product: Seas The Day\n",
      "2025-10-23 13:28:11,861 - INFO - Uploading product 15/8717: Sweet Cheeks\n",
      "2025-10-23 13:28:13,165 - INFO - Successfully created product: Sweet Cheeks\n",
      "2025-10-23 13:28:13,671 - INFO - Uploading product 16/8717: Trust The Timing\n",
      "2025-10-23 13:28:15,106 - INFO - Successfully created product: Trust The Timing\n",
      "2025-10-23 13:28:15,611 - INFO - Uploading product 17/8717: You're Just My Type\n",
      "2025-10-23 13:28:16,829 - INFO - Successfully created product: You're Just My Type\n",
      "2025-10-23 13:28:17,335 - INFO - Uploading product 18/8717: You Are Doing Great\n",
      "2025-10-23 13:28:18,758 - INFO - Successfully created product: You Are Doing Great\n",
      "2025-10-23 13:28:19,264 - INFO - Uploading product 19/8717: Spread Your Wings\n",
      "2025-10-23 13:28:20,586 - INFO - Successfully created product: Spread Your Wings\n",
      "2025-10-23 13:28:21,091 - INFO - Uploading product 20/8717: What's For Dinner?\n",
      "2025-10-23 13:28:22,413 - INFO - Successfully created product: What's For Dinner?\n",
      "2025-10-23 13:28:22,919 - INFO - Uploading product 21/8717: Fork You\n",
      "2025-10-23 13:28:24,202 - INFO - Successfully created product: Fork You\n",
      "2025-10-23 13:28:24,709 - INFO - Uploading product 22/8717: Fork You Greetings Card Pack of 6\n",
      "2025-10-23 13:28:24,800 - ERROR - Failed to create product Fork You Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:24,801 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:25,306 - INFO - Uploading product 23/8717: Hello Sweet Pea\n",
      "2025-10-23 13:28:26,519 - INFO - Successfully created product: Hello Sweet Pea\n",
      "2025-10-23 13:28:27,025 - INFO - Uploading product 24/8717: Hello Sweet Pea Greetings Card Pack of 6\n",
      "2025-10-23 13:28:27,113 - ERROR - Failed to create product Hello Sweet Pea Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:27,113 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:27,615 - INFO - Uploading product 25/8717: I Need A Drink by The 13 Prints\n",
      "2025-10-23 13:28:28,855 - INFO - Successfully created product: I Need A Drink by The 13 Prints\n",
      "2025-10-23 13:28:29,356 - INFO - Uploading product 26/8717: I Need A Drink by The 13 Prints Greetings Card Pack of 6\n",
      "2025-10-23 13:28:29,441 - ERROR - Failed to create product I Need A Drink by The 13 Prints Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:29,442 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:29,947 - INFO - Uploading product 27/8717: It Must Be Love\n",
      "2025-10-23 13:28:31,275 - INFO - Successfully created product: It Must Be Love\n",
      "2025-10-23 13:28:31,782 - INFO - Uploading product 28/8717: It Must Be Love Greetings Card Pack of 6\n",
      "2025-10-23 13:28:31,860 - ERROR - Failed to create product It Must Be Love Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:31,860 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:32,364 - INFO - Uploading product 29/8717: LOVE\n",
      "2025-10-23 13:28:33,596 - INFO - Successfully created product: LOVE\n",
      "2025-10-23 13:28:34,101 - INFO - Uploading product 30/8717: LOVE Greetings Card Pack of 6\n",
      "2025-10-23 13:28:34,183 - ERROR - Failed to create product LOVE Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:34,184 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:34,690 - INFO - Uploading product 31/8717: Nice Bum\n",
      "2025-10-23 13:28:35,975 - INFO - Successfully created product: Nice Bum\n",
      "2025-10-23 13:28:36,481 - INFO - Uploading product 32/8717: Nice Bum Greetings Card Pack of 6\n",
      "2025-10-23 13:28:36,576 - ERROR - Failed to create product Nice Bum Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:36,577 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:37,089 - INFO - Uploading product 33/8717: Nice Cock\n",
      "2025-10-23 13:28:38,477 - INFO - Successfully created product: Nice Cock\n",
      "2025-10-23 13:28:38,981 - INFO - Uploading product 34/8717: Nice Cock Greetings Card Pack of 6\n",
      "2025-10-23 13:28:39,051 - ERROR - Failed to create product Nice Cock Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:39,052 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:39,557 - INFO - Uploading product 35/8717: Nice Tits\n",
      "2025-10-23 13:28:40,919 - INFO - Successfully created product: Nice Tits\n",
      "2025-10-23 13:28:41,425 - INFO - Uploading product 36/8717: Nice Tits Greetings Card Pack of 6\n",
      "2025-10-23 13:28:41,526 - ERROR - Failed to create product Nice Tits Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:41,526 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:42,032 - INFO - Uploading product 37/8717: Valentine by The 13 Prints\n",
      "2025-10-23 13:28:43,469 - INFO - Successfully created product: Valentine by The 13 Prints\n",
      "2025-10-23 13:28:43,975 - INFO - Uploading product 38/8717: Valentine Greetings Card Pack of 6\n",
      "2025-10-23 13:28:44,064 - ERROR - Failed to create product Valentine Greetings Card Pack of 6: 400\n",
      "2025-10-23 13:28:44,065 - ERROR - Response: {\"data\":null,\"error\":{\"status\":400,\"name\":\"ValidationError\",\"message\":\"Invalid key ean_group\",\"details\":{\"key\":\"ean_group\",\"source\":\"body\"}}}\n",
      "2025-10-23 13:28:44,571 - INFO - Uploading product 39/8717: Love Is The Whole Thing II\n",
      "2025-10-23 13:28:45,927 - INFO - Successfully created product: Love Is The Whole Thing II\n",
      "2025-10-23 13:28:46,433 - INFO - Uploading product 40/8717: Bands as Beermats\n",
      "2025-10-23 13:28:47,670 - INFO - Successfully created product: Bands as Beermats\n",
      "2025-10-23 13:28:48,176 - INFO - Uploading product 41/8717: My Vinyl A to Z\n",
      "2025-10-23 13:28:49,307 - INFO - Successfully created product: My Vinyl A to Z\n",
      "2025-10-23 13:28:49,812 - INFO - Uploading product 42/8717: Movie Classics A to Z\n",
      "2025-10-23 13:28:51,028 - INFO - Successfully created product: Movie Classics A to Z\n",
      "2025-10-23 13:28:51,534 - INFO - Uploading product 43/8717: Movie Quotes A to Z\n",
      "2025-10-23 13:28:52,748 - INFO - Successfully created product: Movie Quotes A to Z\n",
      "2025-10-23 13:28:53,252 - INFO - Uploading product 44/8717: Greatest Movies Book Covers A to Z\n",
      "2025-10-23 13:28:54,581 - INFO - Successfully created product: Greatest Movies Book Covers A to Z\n",
      "2025-10-23 13:28:55,088 - INFO - Uploading product 45/8717: Vintage Matchbox Labels A to Z\n"
     ]
    }
   ],
   "source": [
    "# Batch upload with checkpoint support\n",
    "logger.info(\"Starting product upload process...\")\n",
    "\n",
    "# Check if we should resume from checkpoint\n",
    "checkpoint = load_checkpoint()\n",
    "if checkpoint:\n",
    "    resume_choice = input(\"\\nResume from checkpoint? (yes/no): \").strip().lower()\n",
    "    if resume_choice == 'yes':\n",
    "        start_batch = checkpoint['last_batch'] + 1\n",
    "        successful_uploads = checkpoint['successful_uploads']\n",
    "        failed_uploads = checkpoint['failed_uploads']\n",
    "        logger.info(f\"Resuming from batch {start_batch}\")\n",
    "    else:\n",
    "        start_batch = 0\n",
    "        successful_uploads = []\n",
    "        failed_uploads = []\n",
    "        clear_checkpoint()\n",
    "        logger.info(\"Starting fresh upload\")\n",
    "else:\n",
    "    start_batch = 0\n",
    "    successful_uploads = []\n",
    "    failed_uploads = []\n",
    "\n",
    "# Calculate batches\n",
    "total_products = len(product_records)\n",
    "total_batches = (total_products + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "\n",
    "logger.info(f\"Total products: {total_products}\")\n",
    "logger.info(f\"Batch size: {BATCH_SIZE}\")\n",
    "logger.info(f\"Total batches: {total_batches}\")\n",
    "logger.info(f\"Starting from batch: {start_batch + 1}\")\n",
    "\n",
    "# Process batches\n",
    "for batch_idx in range(start_batch, total_batches):\n",
    "    batch_start = batch_idx * BATCH_SIZE\n",
    "    batch_end = min(batch_start + BATCH_SIZE, total_products)\n",
    "    batch = product_records[batch_start:batch_end]\n",
    "    \n",
    "    logger.info(f\"\\n{'='*60}\")\n",
    "    logger.info(f\"Processing batch {batch_idx + 1}/{total_batches} (products {batch_start + 1}-{batch_end})\")\n",
    "    logger.info(f\"{'='*60}\")\n",
    "    \n",
    "    batch_successful = 0\n",
    "    batch_failed = 0\n",
    "    \n",
    "    for i, product_data in enumerate(batch, 1):\n",
    "        product_name = product_data.get('product_parent_name')\n",
    "        \n",
    "        logger.info(f\"Uploading product {batch_start + i}/{total_products}: {product_name}\")\n",
    "        \n",
    "        result = create_product(product_data)\n",
    "        \n",
    "        if result:\n",
    "            successful_uploads.append(product_name)\n",
    "            batch_successful += 1\n",
    "        else:\n",
    "            failed_uploads.append({\n",
    "                'product_name': product_name,\n",
    "                'batch': batch_idx + 1,\n",
    "                'data': product_data\n",
    "            })\n",
    "            batch_failed += 1\n",
    "        \n",
    "        # Small delay between individual uploads\n",
    "        time.sleep(DELAY_BETWEEN_UPLOADS)\n",
    "    \n",
    "    # Save checkpoint after each batch\n",
    "    save_checkpoint(batch_idx, successful_uploads, failed_uploads)\n",
    "    \n",
    "    logger.info(f\"Batch {batch_idx + 1} complete: {batch_successful} successful, {batch_failed} failed\")\n",
    "    \n",
    "    # Delay between batches (except for last batch)\n",
    "    if batch_idx < total_batches - 1:\n",
    "        logger.info(f\"Waiting {DELAY_BETWEEN_BATCHES} seconds before next batch...\")\n",
    "        time.sleep(DELAY_BETWEEN_BATCHES)\n",
    "\n",
    "# Clear checkpoint on successful completion\n",
    "clear_checkpoint()\n",
    "\n",
    "# Display final summary\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"UPLOAD SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total products processed: {total_products}\")\n",
    "print(f\"Successful uploads: {len(successful_uploads)}\")\n",
    "print(f\"Failed uploads: {len(failed_uploads)}\")\n",
    "print(f\"Success rate: {(len(successful_uploads)/total_products*100):.2f}%\")\n",
    "\n",
    "if failed_uploads:\n",
    "    print(f\"\\nFailed products ({len(failed_uploads)}):\")\n",
    "    for failure in failed_uploads[:20]:  # Show first 20\n",
    "        print(f\"  - {failure['product_name']} (batch {failure['batch']})\")\n",
    "    if len(failed_uploads) > 20:\n",
    "        print(f\"  ... and {len(failed_uploads) - 20} more\")\n",
    "    \n",
    "    # Save failed uploads to a separate file for review\n",
    "    failed_file = 'failed_products.json'\n",
    "    with open(failed_file, 'w') as f:\n",
    "        json.dump(failed_uploads, f, indent=2)\n",
    "    print(f\"\\nFailed uploads saved to: {failed_file}\")\n",
    "\n",
    "logger.info(\"Product upload process completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fcbdc1",
   "metadata": {},
   "source": [
    "## Summary and Recommendations\n",
    "\n",
    "### What was done:\n",
    "1. ✅ Loaded CSV data containing product information\n",
    "2. ✅ Filtered for parent products only (excluded variants with hyphens or Frame/Print Size)\n",
    "3. ✅ Built lookup dictionaries from API for foreign key relationships\n",
    "4. ✅ Transformed CSV data to match API schema with foreign key lookups\n",
    "5. ✅ Mapped CSV columns to API field names:\n",
    "   - `Name` → `product_parent_name`\n",
    "   - `SKU` → `product_sku`\n",
    "   - `Artist` → `artist` (foreign key)\n",
    "   - `EEP Campaign Name` → `campaigns` (foreign key array)\n",
    "   - `Primary Colour` → `primary_colours` (foreign key array)\n",
    "   - `Secondary Colour` → `secondary_colours` (foreign key array)\n",
    "   - `EAN Group` → `ean_group` (foreign key)\n",
    "   - `Unbxd Primary Image URL` → `product_artwork_url`\n",
    "6. ✅ Uploaded products in batches with checkpoint support\n",
    "\n",
    "### Key Features:\n",
    "- **Parent/Variant Filtering**: Dual method (hyphen check + Frame/Print Size check)\n",
    "- **Foreign Key Lookups**: Pre-loaded dictionaries for fast relationship mapping\n",
    "- **Multi-colour Handling**: Splits and processes multiple colours per field\n",
    "- **Batch Processing**: 50 products per batch with 2-second delays\n",
    "- **Checkpoint System**: Saves progress after each batch, can resume if interrupted\n",
    "- **Error Tracking**: Saves failed uploads to JSON file for review\n",
    "- **Dimension Conversion**: Converts cm to metres automatically\n",
    "- **Comprehensive Logging**: Tracks all operations with timestamps\n",
    "\n",
    "### Checkpoint System Explained:\n",
    "- **Auto-save**: Progress saved after every batch (50 products)\n",
    "- **Resume**: Can restart from last completed batch if interrupted\n",
    "- **File**: `product_migration_checkpoint.json` stores progress\n",
    "- **Contents**: Batch number, successful uploads, failed uploads, timestamp\n",
    "- **Cleanup**: Automatically deleted on successful completion\n",
    "\n",
    "### Data Quality Notes:\n",
    "- Parent products identified by lack of hyphens AND no Frame/Print Size\n",
    "- Multi-colour fields split on: comma, slash, ampersand, \"and\"\n",
    "- Generic colour terms excluded (multicoloured, various, etc.)\n",
    "- Missing foreign keys logged as warnings but don't block upload\n",
    "- Dimensions converted from cm to metres\n",
    "\n",
    "### Next Steps:\n",
    "1. **Review Failed Uploads**: Check `failed_products.json` for issues\n",
    "2. **Image Migration**: Create script to download and upload images from `product_artwork_url`\n",
    "3. **Variant Migration**: Create separate notebook for product variants\n",
    "4. **Relationship Verification**: Query API to verify all relationships created correctly\n",
    "5. **Data Validation**: Check random sample of products in Strapi admin\n",
    "\n",
    "### Future Improvements:\n",
    "1. **Duplicate Checking**: Query existing products before upload to avoid duplicates\n",
    "2. **Update Capability**: Add logic to update existing products instead of only creating\n",
    "3. **Retry Logic**: Implement automatic retry for failed uploads with exponential backoff\n",
    "4. **Parallel Processing**: Upload multiple batches concurrently (if API supports it)\n",
    "5. **Image Integration**: Download and upload images during product creation\n",
    "6. **Data Validation**: Pre-upload validation for required fields and data types\n",
    "7. **Export Results**: Generate detailed CSV report of upload results\n",
    "8. **Relationship Verification**: Auto-verify foreign keys before upload\n",
    "\n",
    "### Notes on Missing Data:\n",
    "- Products without artists/campaigns/colours still upload (relationships optional)\n",
    "- Image URLs stored for later batch image upload\n",
    "- Product variants excluded from this migration (separate notebook needed)\n",
    "- EAN Groups without matches logged but don't block upload"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eep",
   "language": "python",
   "name": "eep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
